{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T01:09:43.649103Z",
     "start_time": "2024-03-02T01:09:43.645732Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 3060 Ti for training.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # if use GPU, use it\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using {torch.cuda.get_device_name()} for training.\" if torch.cuda.is_available() else \"Using CPU for training\")\n",
    "except:\n",
    "    print(f\"No GPU found. Using CPU for training.\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:45:08.786046Z",
     "start_time": "2024-03-02T00:45:08.737139Z"
    }
   },
   "id": "ed25f2fb5122a30d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_path = 'Dataset/'\n",
    "class_names = sorted(os.listdir(dataset_path))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:45:08.814477Z",
     "start_time": "2024-03-02T00:45:08.786961Z"
    }
   },
   "id": "dd48d04e2c76721d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:45:09.105385Z",
     "start_time": "2024-03-02T00:45:09.100992Z"
    }
   },
   "id": "42bf086e19add31c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Processing images and labels in each folder\n",
    "for batch in data_loader:\n",
    "    images, labels = batch\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:45:50.125866Z",
     "start_time": "2024-03-02T00:45:10.357239Z"
    }
   },
   "id": "bed5f5c376fe648e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_images, total_labels = 0, 0\n",
    "for batch in data_loader:\n",
    "    images, labels = batch\n",
    "    total_images += images.size(0)\n",
    "    total_labels += len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:46:13.560916Z",
     "start_time": "2024-03-02T00:45:50.126983Z"
    }
   },
   "id": "d29ccdf10f095f92",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10287 \n",
      "Total labels: 10287\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total images: {total_images}\", f\"\\nTotal labels: {total_labels}\")    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:46:13.564374Z",
     "start_time": "2024-03-02T00:46:13.561852Z"
    }
   },
   "id": "6a49f13733ac4a3d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  7431\n",
      "Validation:  1312\n",
      "Test:  1544\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(dataset, dataset.targets, test_size=0.15, random_state=42)\n",
    "# Train-Validation Split\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Creating new data_loader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Checking shape of datasets\n",
    "print(\"Train: \", len(train_data))\n",
    "print(\"Validation: \", len(val_data))\n",
    "print(\"Test: \", len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:46:40.235926Z",
     "start_time": "2024-03-02T00:46:13.565317Z"
    }
   },
   "id": "15a414eb93c806b2",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Resnet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:47:15.867773Z",
     "start_time": "2024-03-02T00:47:15.864717Z"
    }
   },
   "id": "43b21ce41fc6ae67",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "resnet_model = ResNet(num_classes=num_classes, pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:47:21.348903Z",
     "start_time": "2024-03-02T00:47:21.171381Z"
    }
   },
   "id": "11d9e29e6293edcc",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Identify train and validation function\n",
    "def train(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T00:47:33.537057Z",
     "start_time": "2024-03-02T00:47:33.530323Z"
    }
   },
   "id": "e897b6bf3cc05a36",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (resnet): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=4, bias=True)\n  )\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 40\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T01:00:19.761926Z",
     "start_time": "2024-03-02T01:00:19.756201Z"
    }
   },
   "id": "53041a68624f641d",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Train Loss: 0.0100, Train Acc: 99.58%, Val Loss: 0.1492, Val Acc: 97.87%\n",
      "Epoch [2/40], Train Loss: 0.0032, Train Acc: 99.89%, Val Loss: 0.1373, Val Acc: 98.17%\n",
      "Epoch [3/40], Train Loss: 0.0013, Train Acc: 99.99%, Val Loss: 0.1394, Val Acc: 98.02%\n",
      "Epoch [4/40], Train Loss: 0.0013, Train Acc: 99.96%, Val Loss: 0.1322, Val Acc: 98.25%\n",
      "Epoch [5/40], Train Loss: 0.0012, Train Acc: 99.97%, Val Loss: 0.1312, Val Acc: 98.02%\n",
      "Epoch [6/40], Train Loss: 0.0009, Train Acc: 99.99%, Val Loss: 0.1281, Val Acc: 98.17%\n",
      "Epoch [7/40], Train Loss: 0.0005, Train Acc: 99.99%, Val Loss: 0.1343, Val Acc: 98.17%\n",
      "Epoch [8/40], Train Loss: 0.0008, Train Acc: 99.99%, Val Loss: 0.1281, Val Acc: 98.17%\n",
      "Epoch [9/40], Train Loss: 0.0008, Train Acc: 99.97%, Val Loss: 0.1239, Val Acc: 98.17%\n",
      "Epoch [10/40], Train Loss: 0.0006, Train Acc: 99.97%, Val Loss: 0.1343, Val Acc: 98.25%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m----> 2\u001B[0m     train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresnet_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     val_loss, val_acc \u001B[38;5;241m=\u001B[39m validate(resnet_model, criterion, val_loader, device)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m], Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m100\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39mtrain_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%, Val Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Val Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m100\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39mval_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[11], line 17\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, criterion, optimizer, train_loader, device)\u001B[0m\n\u001B[1;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 17\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     19\u001B[0m total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(resnet_model, criterion, optimizer, train_loader, device)\n",
    "    val_loss, val_acc = validate(resnet_model, criterion, val_loader, device)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {100 * train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {100 * val_acc:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T01:02:48.077531Z",
     "start_time": "2024-03-02T01:00:23.160521Z"
    }
   },
   "id": "bdda4958e06a6d84",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of Image: meningioma_tumor, Prediction of Model: meningioma_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n",
      "Label of Image: no_tumor, Prediction of Model: no_tumor\n",
      "Label of Image: no_tumor, Prediction of Model: no_tumor\n",
      "Label of Image: meningioma_tumor, Prediction of Model: meningioma_tumor\n",
      "Label of Image: meningioma_tumor, Prediction of Model: meningioma_tumor\n",
      "Label of Image: meningioma_tumor, Prediction of Model: meningioma_tumor\n",
      "Label of Image: no_tumor, Prediction of Model: no_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n",
      "Label of Image: no_tumor, Prediction of Model: no_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n",
      "Label of Image: meningioma_tumor, Prediction of Model: meningioma_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: meningioma_tumor\n",
      "Label of Image: pituitary_tumor, Prediction of Model: pituitary_tumor\n",
      "Label of Image: pituitary_tumor, Prediction of Model: pituitary_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n",
      "Label of Image: pituitary_tumor, Prediction of Model: pituitary_tumor\n",
      "Label of Image: glioma_tumor, Prediction of Model: glioma_tumor\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "# Selecting 20 random image from the test set\n",
    "random_indices = random.sample(range(len(test_data)), 20)\n",
    "\n",
    "for idx in random_indices:\n",
    "    image, label = test_data[idx]\n",
    "\n",
    "    # Export the image to the model\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = resnet_model(image)\n",
    "\n",
    "    # Print by taking the model's prediction and the actual label\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_label = class_names[predicted.item()]\n",
    "    true_label = class_names[label]\n",
    "\n",
    "    print(f\"Label of Image: {true_label}, Prediction of Model: {predicted_label}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T01:16:51.212351Z",
     "start_time": "2024-03-02T01:16:51.147902Z"
    }
   },
   "id": "4fbb3d52d9e18b38",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save model\n",
    "scripted_model = torch.jit.trace(resnet_model, torch.randn(1, 3, 224, 224).to(device)) # convert torch script\n",
    "scripted_model.save('resnet_model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T01:23:27.970746Z",
     "start_time": "2024-03-02T01:23:27.533054Z"
    }
   },
   "id": "24603d56e3578b60",
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
